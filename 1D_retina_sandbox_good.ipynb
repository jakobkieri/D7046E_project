{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGUMsWuGyvnH"
      },
      "source": [
        "# Introduction to the Retina project – D7046E @ LTU.SE\n",
        "\n",
        "This notebook serves as a starting point and playground for investigating what the 1D Retina project is about.\n",
        "The idea is that you should familiarize yourself with both projects and later on decide which project to focus on (retina/SNN or chatbot/ANN)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urDQCbIYyvnJ"
      },
      "source": [
        "# Enable inline plots in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Import library functions needed\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "# Set default figure size\n",
        "plt.rcParams['figure.figsize'] = [6,6]\n",
        "\n",
        "# Function that is used to plot spike times\n",
        "def rasterplot(ax, x, y, x_label, y_label):\n",
        "    ax.set_xlabel(x_label)\n",
        "    ax.set_ylabel(y_label)\n",
        "    ax.scatter(x, y, marker='|')\n",
        "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ9k1B9NyvnK"
      },
      "source": [
        "# Basic data generator\n",
        "\n",
        "The following animation illustrates a simple motion detection task. A bright spot is moving across a one-dimensonal array of virtual receptor neurons.\n",
        "\n",
        "![Concept illustration](https://drive.google.com/uc?export=view&id=1dc4TQ84ui5i9oVnGH9Au5sZfHKzt-2jd)\n",
        "\n",
        "The task is to determine whether the pattern is moving and whether it is moving towards the left or right. The following code implements a basic spike data generator inspired by the animation above. For simplicity it is assumed that a bright spot is moving at constant speed back and forth, and that one spike is generated when the bright spot is passing over a receptor neuron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmBynoI5yvnL",
        "outputId": "f2118ccd-604c-459c-dfb9-cfe06c0fb404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "####################################################################################################\n",
        "# Simulation parameters\n",
        "dt = 1e-4                    # Timestep\n",
        "t = np.arange(0,20000)*dt    # Simulation time array t\n",
        "num_receptors = 10           # Number of receptor neurons\n",
        "speed = 20                   # Speed of bright spot, number of receptor neurons passed per second\n",
        "####################################################################################################\n",
        "\n",
        "plot_t = []                  # Time of spikes\n",
        "plot_n = []                  # Receptor neuron id's\n",
        "currtime = 0                 # Time when a spike is fired\n",
        "neuronid = 0                 # Neuron that fires a spike\n",
        "stepdir = 1                  # Is the bright spot moving towards the right (1) or left (-1)\n",
        "timestep = 1.0/(speed-1)     # Time between spikes generated by nearby receptor neurons\n",
        "\n",
        "# Make placeholders for spike time arrays to be used for SNN simulation\n",
        "spikes = []\n",
        "for i in range(num_receptors):\n",
        "    spikes.append([])\n",
        "\n",
        "# Generate and plot spikes from receptor neurons\n",
        "while currtime < t[-1]:\n",
        "    plot_t.append(currtime)\n",
        "    plot_n.append(neuronid)\n",
        "    spikes[neuronid].append(currtime)\n",
        "    if neuronid == 0 and stepdir == -1:\n",
        "        stepdir = 1\n",
        "    elif neuronid == (num_receptors-1) and stepdir == 1:\n",
        "        stepdir = -1\n",
        "    neuronid += stepdir\n",
        "    currtime += timestep\n",
        "\n",
        "# Plot spikes\n",
        "fig, ax = plt.subplots()\n",
        "rasterplot(ax, plot_t, plot_n,'Time [s]','Receptor neuron ID')\n",
        "ax.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCvIJCIlyvnM"
      },
      "source": [
        "# Implement your first motion-detection SNN\n",
        "\n",
        "There is a direction-selective network example in [Neuronify](https://ovilab.net/neuronify/), which is illustrated below. This network is designed so that the output neuron tends to fire a spike when the inputs are touched from right to left, but not when touched from left to right (with some limitations on the touching speed).\n",
        "\n",
        "![First network implementation](https://drive.google.com/uc?export=view&id=1ZIyhUCtNebN1StlYCKEnC0qgXMZAF8d-)\n",
        "\n",
        "Can you simulate this network using the code from SNN Exercise 1 and the input spikes provided by the data generator above? Can you modify the parameters of the simulated network so that it becomes direction selective?\n",
        "\n",
        "If you succeed with this task then you have designed your first SNN vision system capable of basic motion detection!\n",
        "\n",
        "**Note:** You need to complete SNN Exercise 1 to acquire the necessary background knowledge for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hijVbiBkyvnN"
      },
      "source": [
        "# To simulate the spikes from the receptor neurons you will need an additional neuron constructor defined as\n",
        "\n",
        "def spike_generator(spike_times):\n",
        "    # Generates spikes at time points defined by the sorted list 'spike_t'\n",
        "    return {\n",
        "        'type'      : 'generator',\n",
        "        'spike_t'   : spike_times              # Array of spike times, separated by at least dt\n",
        "}\n",
        "\n",
        "# To incorporate this neuron type in the simulator you will need to update the spikegen(dt,t,neurons) function\n",
        "\n",
        "def spikegen(dt, t, neurons):\n",
        "    # This function implements the non-linear spike generation mechanism\n",
        "    spikes = []\n",
        "    for i,n in enumerate(neurons):\n",
        "        if n['type'] in ['lif_cic','lif']:\n",
        "            if n['u'] > n['u_thres']:\n",
        "                n['u'] = n['u_reset']\n",
        "                spikes.append(i)\n",
        "        elif n['type'] == 'generator':\n",
        "            j = np.searchsorted(n['spike_t'], t, side='right')\n",
        "            if j>0 and t-n['spike_t'][j-1]<dt:\n",
        "                spikes.append(i)\n",
        "    return spikes\n",
        "\n",
        "# With these modifications of the simulator code you should be able to simulate the receptor neurons using\n",
        "# spike_generator neurons initialized with the spike time arrays produced by the data generator code above.\n",
        "\n",
        "# The construction of neurons and configuration of synapses should be done in a similar way as in SNN Exercise 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulation parameters\n",
        "dt = 5e-2\n",
        "t = np.arange(0, 20000) * dt  # Time array\n",
        "num_receptors = 10\n",
        "num_steps = len(t)\n",
        "window_size = 2  # Number of frames per sample\n",
        "\n",
        "# Initialize motion variables\n",
        "position = 0  # Start at Receptor 0\n",
        "direction = 1  # 1 = moving right, -1 = moving left\n",
        "speed = 20  # Neurons per second\n",
        "\n",
        "# Generate correct bouncing motion\n",
        "positions = []\n",
        "directions = []\n",
        "\n",
        "for i in range(num_steps):\n",
        "    positions.append(position)\n",
        "    directions.append(direction)\n",
        "    position += direction * speed * dt\n",
        "\n",
        "    # Reverse direction at boundaries (0 and 9)\n",
        "    if position >= num_receptors - 1 or position <= 0:\n",
        "        direction *= -1\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "positions = np.clip(np.round(positions).astype(int), 0, num_receptors - 1)\n",
        "directions = np.array(directions)\n",
        "\n",
        "# Create dataset (binary activation for receptors)\n",
        "dataset = np.zeros((num_steps, num_receptors), dtype=int)\n",
        "dataset[np.arange(num_steps), positions] = 1\n",
        "\n",
        "# Create sequences of frames (samples)\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(num_steps - window_size):\n",
        "    sample = dataset[i : i + window_size].flatten()  # Flatten sequence\n",
        "    label = directions[i + window_size - 1]  # Direction at the last frame of the sequence\n",
        "    X.append(sample)\n",
        "    y.append(label)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(X, columns=[f\"Frame_{i}_Receptor_{j}\" for i in range(window_size) for j in range(num_receptors)])\n",
        "df.insert(0, \"Direction\", y)  # Add direction label\n",
        "\n",
        "# Save the dataset\n",
        "df.to_csv(\"data_sequences.csv\", index=False)\n",
        "\n",
        "# Print checks\n",
        "print(df.shape)  # (num_samples, window_size * num_receptors + 1)\n",
        "#print(df.head(10))  # Check first 10 samples\n",
        "#print(df[0:1])\n",
        "###########################################################WITHOUT NOISE###########################################################"
      ],
      "metadata": {
        "id": "LN_1pIXlFNlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e7bc9e-25c3-486d-a591-5d89e6c1a528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19998, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulation parameters\n",
        "dt = 5e-2\n",
        "t = np.arange(0, 20000) * dt  # Time array\n",
        "num_receptors = 10\n",
        "num_steps = len(t)\n",
        "window_size = 2  # Number of frames per sample\n",
        "noise_level = 0.1  # Noise level for receptor activation\n",
        "flip_prob = 0.02  # Probability of flipping direction labels\n",
        "\n",
        "# Initialize motion variables\n",
        "position = 0  # Start at Receptor 0\n",
        "direction = 1  # 1 = moving right, -1 = moving left\n",
        "speed = 20  # Neurons per second\n",
        "\n",
        "# Generate correct bouncing motion\n",
        "positions = []\n",
        "directions = []\n",
        "\n",
        "for i in range(num_steps):\n",
        "    positions.append(position)\n",
        "    directions.append(direction)\n",
        "    position += direction * speed * dt\n",
        "\n",
        "    # Reverse direction at boundaries (0 and 9)\n",
        "    if position >= num_receptors - 1 or position <= 0:\n",
        "        direction *= -1\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "positions = np.clip(np.round(positions).astype(int), 0, num_receptors - 1)\n",
        "directions = np.array(directions)\n",
        "\n",
        "# Introduce random flips in direction labels\n",
        "flip_mask = np.random.rand(num_steps) < flip_prob\n",
        "directions[flip_mask] *= -1\n",
        "\n",
        "# Create dataset (binary activation for receptors) with noise\n",
        "dataset = np.zeros((num_steps, num_receptors))\n",
        "dataset[np.arange(num_steps), positions] = 1\n",
        "\n",
        "dataset += noise_level * np.random.randn(num_steps, num_receptors)  # Add Gaussian noise\n",
        "dataset = np.clip(dataset, 0, 1)  # Keep values in valid range\n",
        "\n",
        "# Create sequences of frames (samples)\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(num_steps - window_size):\n",
        "    sample = dataset[i : i + window_size].flatten()  # Flatten sequence\n",
        "    label = directions[i + window_size - 1]  # Direction at the last frame of the sequence\n",
        "    X.append(sample)\n",
        "    y.append(label)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(X, columns=[f\"Frame_{i}_Receptor_{j}\" for i in range(window_size) for j in range(num_receptors)])\n",
        "df.insert(0, \"Direction\", y)  # Add direction label\n",
        "\n",
        "# Save the dataset\n",
        "df.to_csv(\"data_sequences_noisy.csv\", index=False)\n",
        "\n",
        "# Print checks\n",
        "print(df.shape)  # (num_samples, window_size * num_receptors + 1)\n",
        "\n",
        "\n",
        "\n",
        "###########################################################WITH NOISE###########################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_C2QWWTFXY-",
        "outputId": "b7d1b752-c0d5-4c3a-ae50-2ad0e48185ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19998, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLIxcQpGyvnN"
      },
      "source": [
        "# Further project work\n",
        "\n",
        "The challenge for the **1D Retina project** is to develop a more advanced vision system for (1D) motion classification, which is not limited to one specific pattern like the bright spot in the basic data generator above.\n",
        "\n",
        "For example, you could consider using an open image dataset for training, validation and testing. For testing, the output of a webcam could optionally be considered. The delta modulator concept introduced in SNN Exercise 1 could potentially be used to convert pixel intensities to spikes. Optionally, you can use a [DAVIS346 neuromorphic vision sensor](https://inivation.github.io/inivation-docs/Hardware%20user%20guides/User_guide_-_DAVIS346.html) to record your own dataset.\n",
        "\n",
        "Some inspiration for the SNN network architecture and training protocol can be obtained also from SNN Exercise 2. The [Reichardt Detector](https://en.wikipedia.org/wiki/Motion_perception#The_Reichardt-Hassenstein_model) is one starting point. For further inspiration, consider for example [motion detection in insects](https://link.springer.com/content/pdf/10.1007/s00359-019-01375-9.pdf).\n",
        "\n",
        "In addition to considering differnt types of receptor models and SNN architectures for efficient and reliable motion classification, you can consider using other SNN simulators like [Brian2](https://brian2.readthedocs.io). Optionally you can consider using accelerators like [Brian2GeNN](https://brian2genn.readthedocs.io/en/stable/introduction/).\n",
        "\n",
        "The possibilities for exploration are endless! How does the human retina work?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch\n",
        "\n",
        "#!pip install dv-processing\n",
        "\n",
        "# Importing libraries for working with spiking neural networks (SNNs), machine learning, data visualization, and animations.\n",
        "import snntorch as snn  # Library for working with spiking neural networks in PyTorch\n",
        "from snntorch import spikeplot as splt  # Submodule for plotting spikes and visualizations\n",
        "from snntorch import spikegen  # Submodule for generating spike data or configuring spike-related parameters\n",
        "\n",
        "import torch  # PyTorch deep learning library\n",
        "import torch.nn as nn  # Neural network module in PyTorch\n",
        "from torch.utils.data import DataLoader  # DataLoader for handling datasets in PyTorch\n",
        "from torchvision import datasets, transforms  # Modules for loading datasets and image transformations\n",
        "import matplotlib.pyplot as plt  # Matplotlib's plotting module\n",
        "import numpy as np  # NumPy for numerical computing\n",
        "import itertools  # Standard library module for creating iterators\n",
        "\n",
        "import time  # Standard library module for time-related tasks\n",
        "from matplotlib.animation import FuncAnimation  # For creating animations in Matplotlib\n",
        "from IPython.display import Image  # For displaying images within the IPython environment\n",
        "\n",
        "# Importing libraries for data splitting and handling\n",
        "from sklearn.model_selection import train_test_split  # Function for splitting datasets\n",
        "import pandas as pd  # Pandas for data manipulation and analysis\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4S_ndbFue2",
        "outputId": "152840ae-f6a3-4059-d7f3-41f12a98a87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDje6uuMz7uA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "\n",
        "# Define SNN Model\n",
        "class SpikingNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(20, 50)  # Input layer (20) → Hidden layer (50)\n",
        "        self.lif1 = snn.Leaky(beta=0.9)  # Leaky Integrate-and-Fire neuron\n",
        "\n",
        "        self.fc2 = nn.Linear(50, 10)  # Hidden layer (50) → Hidden layer (10)\n",
        "        self.lif2 = snn.Leaky(beta=0.9)\n",
        "\n",
        "        self.fc3 = nn.Linear(10, 1)  # Hidden layer (10) → Output layer (1)\n",
        "        self.lif3 = snn.Leaky(beta=0.9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, mem1 = self.lif1(self.fc1(x))  # First layer\n",
        "        spk2, mem2 = self.lif2(self.fc2(mem1))  # Second layer\n",
        "        spk3, mem3 = self.lif3(self.fc3(mem2))  # Output layer\n",
        "\n",
        "        return mem3  # Return membrane potential (continuous value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"data_sequences_noisy.csv\")\n",
        "\n",
        "# Extract features (X) and labels (y)\n",
        "X = df.iloc[:, 1:].values.astype(np.float32)  # All columns except 'Direction'\n",
        "y = df.iloc[:, 0].values.astype(np.float32)   # 'Direction' column (labels)\n",
        "\n",
        "# Convert labels to {0,1} for binary classification\n",
        "y[y == -1] = 0  # Convert -1 to 0\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X)\n",
        "y_tensor = torch.tensor(y).unsqueeze(1)  # Add extra dimension for single neuron output\n",
        "\n",
        "# Split dataset (60% train, 20% val, 20% test)\n",
        "num_samples = len(X_tensor)\n",
        "train_size = int(0.6 * num_samples)\n",
        "val_size = int(0.2 * num_samples)\n",
        "test_size = num_samples - train_size - val_size  # Ensure total adds up\n",
        "\n",
        "train_data, val_data, test_data = random_split(\n",
        "    TensorDataset(X_tensor, y_tensor),\n",
        "    [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# DataLoader setup\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# DataLoader for test set\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "X12zhq2fSyjc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d083a248-55a0-404e-9fd8-ab44dc3a7caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-35452d55be40>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mval_size\u001b[0m  \u001b[0;31m# Ensure total adds up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m train_data, val_data, test_data = random_split(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import snntorch as snn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define SNN Model\n",
        "class SpikingNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(20, 50)\n",
        "        self.lif1 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.lif2 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "        self.lif3 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()  # Reset membrane state\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        spk1, mem1 = self.lif1(self.fc1(x), mem1)\n",
        "        spk2, mem2 = self.lif2(self.fc2(mem1), mem2)\n",
        "        spk3, mem3 = self.lif3(self.fc3(mem2), mem3)\n",
        "\n",
        "        return mem3  # Membrane potential as output\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SpikingNN().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with model saving\n",
        "num_epochs = 20\n",
        "best_val_loss = float(\"inf\")  # Track best validation loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            predictions = (torch.sigmoid(outputs) > 0.5).float()  # Convert logits to binary 0/1\n",
        "            correct += (predictions == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # **Save model if it's the best one so far**\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), \"best_snn_model.pth\")\n",
        "        print(\"New best model - saved\")\n",
        "\n",
        "print(\"Training complete. Best model saved as 'best_snn_model.pth'\")"
      ],
      "metadata": {
        "id": "RvVKzHM3wW3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e12491a-8c60-4917-b44f-c74cd522e079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 0.5594, Val Loss: 0.3834, Val Acc: 0.8555\n",
            "New best model - saved\n",
            "Epoch 2/20 - Train Loss: 0.3018, Val Loss: 0.2371, Val Acc: 0.9167\n",
            "New best model - saved\n",
            "Epoch 3/20 - Train Loss: 0.2536, Val Loss: 0.2283, Val Acc: 0.9177\n",
            "New best model - saved\n",
            "Epoch 4/20 - Train Loss: 0.2496, Val Loss: 0.2292, Val Acc: 0.9180\n",
            "Epoch 5/20 - Train Loss: 0.2497, Val Loss: 0.2296, Val Acc: 0.9170\n",
            "Epoch 6/20 - Train Loss: 0.2494, Val Loss: 0.2281, Val Acc: 0.9172\n",
            "New best model - saved\n",
            "Epoch 7/20 - Train Loss: 0.2497, Val Loss: 0.2288, Val Acc: 0.9147\n",
            "Epoch 8/20 - Train Loss: 0.2486, Val Loss: 0.2280, Val Acc: 0.9140\n",
            "New best model - saved\n",
            "Epoch 9/20 - Train Loss: 0.2484, Val Loss: 0.2279, Val Acc: 0.9147\n",
            "New best model - saved\n",
            "Epoch 10/20 - Train Loss: 0.2488, Val Loss: 0.2286, Val Acc: 0.9150\n",
            "Epoch 11/20 - Train Loss: 0.2497, Val Loss: 0.2304, Val Acc: 0.9140\n",
            "Epoch 12/20 - Train Loss: 0.2490, Val Loss: 0.2281, Val Acc: 0.9152\n",
            "Epoch 13/20 - Train Loss: 0.2485, Val Loss: 0.2277, Val Acc: 0.9137\n",
            "New best model - saved\n",
            "Epoch 14/20 - Train Loss: 0.2481, Val Loss: 0.2290, Val Acc: 0.9145\n",
            "Epoch 15/20 - Train Loss: 0.2479, Val Loss: 0.2282, Val Acc: 0.9165\n",
            "Epoch 16/20 - Train Loss: 0.2484, Val Loss: 0.2266, Val Acc: 0.9150\n",
            "New best model - saved\n",
            "Epoch 17/20 - Train Loss: 0.2488, Val Loss: 0.2274, Val Acc: 0.9155\n",
            "Epoch 18/20 - Train Loss: 0.2493, Val Loss: 0.2314, Val Acc: 0.9145\n",
            "Epoch 19/20 - Train Loss: 0.2486, Val Loss: 0.2290, Val Acc: 0.9157\n",
            "Epoch 20/20 - Train Loss: 0.2493, Val Loss: 0.2282, Val Acc: 0.9160\n",
            "Training complete. Best model saved as 'best_snn_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the same SNN model as before\n",
        "class SpikingNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(20, 50)\n",
        "        self.lif1 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.lif2 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "        self.lif3 = snn.Leaky(beta=0.9, reset_mechanism=\"zero\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        spk1, mem1 = self.lif1(self.fc1(x), mem1)\n",
        "        spk2, mem2 = self.lif2(self.fc2(mem1), mem2)\n",
        "        spk3, mem3 = self.lif3(self.fc3(mem2), mem3)\n",
        "\n",
        "        return mem3  # Output membrane potential\n",
        "\n",
        "# Load the best model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SpikingNN().to(device)\n",
        "model.load_state_dict(torch.load(\"best_snn_model.pth\"))\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy\n",
        "        predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (predictions == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "# Compute final test loss and accuracy\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_acc = correct / total\n",
        "\n",
        "print(f\"✅ Test Loss: {avg_test_loss:.4f}, Test Accuracy: {100*test_acc:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sirPTJY53BeE",
        "outputId": "7f4526d6-b1ad-421e-e2d2-06f979793179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-5076b9f8f06e>:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_snn_model.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test Loss: 0.2347, Test Accuracy: 91.8020%\n"
          ]
        }
      ]
    }
  ]
}